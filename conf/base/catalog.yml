# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html
#
# We support interacting with a variety of data stores including local file systems, cloud, network and HDFS
#
# The Data Catalog supports being able to reference the same file using two different DataSet implementations
# (transcoding), templating and a way to reuse arguments that are frequently repeated. See more here:
# https://kedro.readthedocs.io/en/stable/data/data_catalog.html
#

#######################
#  Team C            #
#######################


sdg_data:
  type: pandas.CSVDataSet
  #filepath: data/01_raw/train.csv
  filepath: s3://internship-sdg-2022/kedro/data/01_raw/train.csv
  credentials: s3_credentials
  layer: raw
  load_args:
    sep: '\t'

osdg_preprocessed_data:
  type: pandas.CSVDataSet
  #filepath: data/02_intermediate/osdg_preprocessed_data.csv
  filepath: s3://internship-sdg-2022/kedro/data/02_intermediate/osdg_preprocessed_data.csv
  credentials: s3_credentials
  #file_format: csv
  load_args:
    sep: ','
  save_args:
    index: False
    sep: ','
    header: True
    encoding: "utf-8"


#######################
#  Team A             #
#######################

q_and_a_data:
  type: pandas.CSVDataSet
  #filepath: data/02_intermediate/q_and_a_data.csv
  filepath: s3://internship-sdg-2022/kedro/data/02_intermediate/q_and_a_data.csv
  credentials: s3_credentials
  #file_format: csv
  load_args:
    sep: ','
  save_args:
    index: False
    sep: ','
    header: True
    encoding: "utf-8"

articles:
  type: pandas.SQLTableDataSet
  credentials: rds_connection_credentials
  table_name: shell_webscraped_articles
  save_args:
    if_exists: replace

# articles_data:
#   type: pandas.CSVDataSet
#   filepath: /home/kedro/data/01_raw/articles.csv

#######################
#  Team B - Twitter   #
#######################


#sdg text data for tutorial example
twitter_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/tweets.csv
  layer: raw


#The twitter text data after being cleaned (it has a new column called 'clean_text')

clean_tweet_data:
  type: pandas.CSVDataSet
  #filepath: data/02_intermediate/clean_tweet_data.csv
  #layer: intermediate
  filepath: s3://internship-sdg-2022/kedro/data/02_intermediate/clean_tweet_data.csv
  credentials: s3_credentials
  #file_format: csv
  load_args:
    sep: ','
  save_args:
    index: False
    sep: ','
    header: True
    encoding: "utf-8"


#The twitter text data after being labelled (sentiment)
labelled_twitter_data:
  type: pandas.CSVDataSet
  #filepath: data/03_primary/labelled_twitter_data.csv
  #layer: primary
  filepath: s3://internship-sdg-2022/kedro/data/03_primary/labelled_twitter_data.csv
  credentials: s3_credentials
  #file_format: csv
  load_args:
    sep: ','
  save_args:
    index: False
    sep: ','
    header: True
    encoding: "utf-8"


# models

#classifier:
#  type: pickle.PickleDataSet
#  filepath: data/06_models/sdg_classifier.pickle
#  versioned: true
#  layer: models

tweet_text_data:
  type: pandas.CSVDataSet
  filepath: data/01_raw/tweets_2.csv
  layer: raw
  #load_args:
    #sep: '/t'

# raw_tweet_text_data:
#   type: pandas.CSVDataSet
#   filepath: data/01_raw/tweets_2.csv
#   layer: raw


clean_label_data:
  type: pandas.CSVDataSet
  #filepath: data/02_intermediate/clean_label_data.csv
  #layer: intermediate
  filepath: s3://internship-sdg-2022/kedro/data/02_intermediate/clean_tweet_data.csv
  credentials: s3_credentials
  #file_format: csv
  load_args:
    sep: ','
  save_args:
    index: False
    sep: ','
    header: True
    encoding: "utf-8"

  

raw_data:
  type: pandas.SQLQueryDataSet
  credentials: rds_connection_credentials
  sql: SELECT * FROM twitter_stream 

rds_connection:
  type: pandas.SQLTableDataSet
  credentials: rds_connection_credentials
  table_name: twitter_stream
  save_args:
    if_exists: replace

save_data_to_rds:
  type: pandas.SQLTableDataSet
  credentials: rds_connection_credentials
  table_name: twitter_stream
  save_args:
    schema: public
    if_exists: append



#######################
#  Models             #
#######################

# saving the text classification model

#text_classification.sdg_classifier:
#  type: pickle.PickleDataSet
#  filepath: data/06_models/sdg_classifier.pickle
#  versioned: true
#  layer: models

text_classification.vectorizer:
  type: pickle.PickleDataSet
  filepath: s3://internship-sdg-2022/models/vectorizer.pickle
  credentials: s3_credentials
  backend: pickle

text_classification.sdg_classifier:
  type: pickle.PickleDataSet
  filepath: s3://internship-sdg-2022/models/sdg_classifier.pickle
  credentials: s3_credentials
  backend: pickle

 

